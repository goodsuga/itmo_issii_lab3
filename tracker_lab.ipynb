{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from mlflow import MlflowClient\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataloader import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Работаем над воспроизводимостью\n",
    "# Make the code reproducible\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "pl.seed_everything(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 0. Создаем модель, с которой будем работать\n",
    "# Step 0. Create the model, which we will be working with\n",
    "\n",
    "\n",
    "# Шаг 0.1 Готовим класс датасета для лайтнинга\n",
    "# Step 0.1 Preparing the Dataset class for Pytorch Lightning\n",
    "from pytorch_lightning.core.module import LightningModule\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "\n",
    "\n",
    "class TorchModelData(Dataset):\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "# Шаг 0.2 Описываем модель\n",
    "# Step 0.2 Describing the model\n",
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_features: int,\n",
    "            layer_neurons: List[int],\n",
    "            activation_function_class,\n",
    "            opt=torch.optim.NAdam,\n",
    "            lr=0.01\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._in_features = in_features\n",
    "        self._layer_neurons = layer_neurons\n",
    "        self._lr = lr\n",
    "        self._opt = opt\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(layer_neurons)):\n",
    "            if i == 0:\n",
    "                input_neurons = in_features\n",
    "            else:\n",
    "                input_neurons = layer_neurons[i-1]\n",
    "            \n",
    "            layers.append(torch.nn.Linear(input_neurons, layer_neurons[i]))\n",
    "            if i != (len(layer_neurons) - 1):\n",
    "                layers.append(activation_function_class())\n",
    "        \n",
    "        self._model = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if \"cuda\" in str(self.device) and not \"cuda\" in str(x.device):\n",
    "            return self._model(x.cuda())\n",
    "        else:\n",
    "            return self._model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self.forward(x)\n",
    "        loss = torch.mean((y - preds)**2)\n",
    "        self.log(\"train_mse\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self.forward(x)\n",
    "        loss = torch.mean((y - preds)**2)\n",
    "        self.log(\"val_mse\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = self._opt(self.parameters(), lr=self._lr)\n",
    "        return opt\n",
    "    \n",
    "\n",
    "# Шаг 0.3 - создаем обратный вызов pytorch lightning, где будем фиксировать метрики по эпохам\n",
    "# для MLFlow\n",
    "# Step 0.3 - Make lightning callback to fix metrics by epoch\n",
    "\n",
    "class MlflowMetricCallback(pl.Callback):\n",
    "    def __init__(self, train_tensor, val_tensor, y_train, y_val):\n",
    "        super().__init__()\n",
    "        self._train_X = train_tensor\n",
    "        self._val_X = val_tensor\n",
    "        self._y_train = y_train.detach().cpu().numpy()\n",
    "        self._y_val = y_val.detach().cpu().numpy()\n",
    "\n",
    "    def on_train_epoch_end(self, trainer: Trainer, pl_module: LightningModule):\n",
    "        preds_train = pl_module(self._train_X).detach().cpu().numpy()\n",
    "        preds_val = pl_module(self._val_X).detach().cpu().numpy()\n",
    "\n",
    "        epoch = trainer.current_epoch\n",
    "\n",
    "        metrics = {\n",
    "            \"Train MAE\": mean_absolute_error(self._y_train, preds_train),\n",
    "            \"Train R2\": r2_score(self._y_train, preds_train),\n",
    "            \"Eval MAE\": mean_absolute_error(self._y_val, preds_val),\n",
    "            \"Eval R2\": r2_score(self._y_val, preds_val)\n",
    "        }\n",
    "\n",
    "        mlflow.log_metrics(metrics, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.284354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.178794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.696601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.768036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.401235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                                 676.0         28   \n",
       "1                                                 676.0         28   \n",
       "2                                                 594.0        270   \n",
       "3                                                 594.0        365   \n",
       "4                                                 825.5        360   \n",
       "...                                                 ...        ...   \n",
       "1025                                              768.3         28   \n",
       "1026                                              813.4         28   \n",
       "1027                                              780.0         28   \n",
       "1028                                              788.9         28   \n",
       "1029                                              761.5         28   \n",
       "\n",
       "      Concrete compressive strength(MPa, megapascals)   \n",
       "0                                            79.986111  \n",
       "1                                            61.887366  \n",
       "2                                            40.269535  \n",
       "3                                            41.052780  \n",
       "4                                            44.296075  \n",
       "...                                                ...  \n",
       "1025                                         44.284354  \n",
       "1026                                         31.178794  \n",
       "1027                                         23.696601  \n",
       "1028                                         32.768036  \n",
       "1029                                         32.401235  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Шаг 1. Загружаем данные\n",
    "# Step 1. Load the data\n",
    "data = pd.read_excel(\"Concrete_Data.xls\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"Concrete compressive strength(MPa, megapascals) \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 2. Разбиваем данные на тренировку и валидацию\n",
    "# Step 2. Split data into train and validation\n",
    "\n",
    "X_train, X_val = train_test_split(data, test_size=0.2, shuffle=True, random_state=42)\n",
    "y_train, y_val = X_train.pop(target_name), X_val.pop(target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick look at the target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "y_train.hist(bins=50, ax=axs[0])\n",
    "y_val.hist(bins=50, ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 3.0 Трансформируем данные\n",
    "# Step 3.0 Transforming data\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "sc = RobustScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "train_tensor = sc.transform(X_train)\n",
    "train_tensor = torch.as_tensor(train_tensor, dtype=torch.float32)\n",
    "\n",
    "val_tensor = sc.transform(X_val)\n",
    "val_tensor = torch.as_tensor(val_tensor, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.as_tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "y_val_tensor = torch.as_tensor(y_val.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 4.0 Создаем загрузчики данных\n",
    "# Step 4.0 Making dataloaders\n",
    "\n",
    "train_ds = TorchModelData(train_tensor, y_train_tensor)\n",
    "val_ds = TorchModelData(val_tensor, y_val_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=256)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 21    \n",
      "--------------------------------------\n",
      "21        Trainable params\n",
      "0         Non-trainable params\n",
      "21        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 132.13it/s, v_num=94, val_mse=1.52e+3, train_mse=1.57e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 118.41it/s, v_num=94, val_mse=1.52e+3, train_mse=1.57e+3]\n"
     ]
    }
   ],
   "source": [
    "# Шаг 5.0 Обучаем тестовую модель\n",
    "# Step 5.0 Training a debug model\n",
    "\n",
    "model = LightningModel(\n",
    "    train_tensor.shape[1],\n",
    "    [2, 1],\n",
    "    torch.nn.ReLU\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator='cpu')\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/108242481070769059', creation_time=1715874255164, experiment_id='108242481070769059', last_update_time=1715874255164, lifecycle_stage='active', name='Concrete_Models', tags={'mlflow.note.content': 'Experiment on forecasting concrete strength',\n",
      " 'project_name': 'concrete-strength'}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1715596986922, experiment_id='0', last_update_time=1715596986922, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "# Обучение прошло успешно, подключаем MLFLow\n",
    "# Сначала запустим локальный сервер\n",
    "# Для этого в терминале:\n",
    "# mlflow server --host 127.0.0.1 --port 8080\n",
    "\n",
    "# Training succeeded, now to connect to MLFlow\n",
    "# To do that, start up the local server\n",
    "# In terminal:\n",
    "# mlflow server --host 127.0.0.1 --port 8080\n",
    "\n",
    "# Далее, при включенном сервере:\n",
    "# Next, when the server is running:\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 6.0 Создаем эксперимент, если его еще нет\n",
    "# Step 6.0 Create the experiment, if it doesn't already exist\n",
    "\n",
    "concrete_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'concrete-strength'\"\n",
    ")\n",
    "\n",
    "if len(concrete_experiment) == 0:\n",
    "    experiment_description = (\n",
    "        \"Experiment on forecasting concrete strength\"\n",
    "    )\n",
    "\n",
    "    # Добавляем теги\n",
    "    # Add tags\n",
    "    experiment_tags = {\n",
    "        \"project_name\": \"concrete-strength\",\n",
    "        \"mlflow.note.content\": experiment_description,\n",
    "    }\n",
    "\n",
    "    # Создаем эксперимент, даем ему уникальное имя\n",
    "    # Create the experiment, give it a unique name\n",
    "    concrete_experiment = client.create_experiment(\n",
    "        name=\"Concrete_Models\", tags=experiment_tags\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 41    \n",
      "--------------------------------------\n",
      "41        Trainable params\n",
      "0         Non-trainable params\n",
      "41        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4/4 [00:00<00:00, 147.18it/s, v_num=95, val_mse=1.16e+3, train_mse=1.23e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4/4 [00:00<00:00, 131.31it/s, v_num=95, val_mse=1.16e+3, train_mse=1.23e+3]\n",
      "{'Final Eval MAE': 29.585546, 'Final Eval R2': -3.3467434334704054}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Шаг 7.0 Обучаем нормальный бейзлайн, логируем параметры\n",
    "# Step 7.0 Now to train a proper baseline with metric logging\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "experiment = mlflow.set_experiment(\"Concrete_Models\")\n",
    "\n",
    "run_name = \"Baseline Model\"\n",
    "artifact_path = \"BaselineModel\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [4, 1],\n",
    "        \"activation_function_class\": torch.nn.ReLU\n",
    "    }\n",
    "\n",
    "    # train the model\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=15, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    "\n",
    "    # Write run data to MLFlow\n",
    " \n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 41    \n",
      "--------------------------------------\n",
      "41        Trainable params\n",
      "0         Non-trainable params\n",
      "41        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4/4 [00:00<00:00, 135.39it/s, v_num=96, val_mse=280.0, train_mse=295.0] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4/4 [00:00<00:00, 122.60it/s, v_num=96, val_mse=280.0, train_mse=295.0]\n",
      "{'Final Eval MAE': 13.125069, 'Final Eval R2': 0.018272090494686588}\n"
     ]
    }
   ],
   "source": [
    "# Гипотеза 1: Неподходящий оптимизатор: попробуем SGD\n",
    "# Hypothesis 1: wrong optimizer, try SGD\n",
    "\n",
    "run_name = \"SGD Model\"\n",
    "artifact_path = \"SGDModel\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [4, 1],\n",
    "        \"activation_function_class\": torch.nn.ReLU,\n",
    "        \"opt\": torch.optim.SGD,\n",
    "        \"lr\": 0.01\n",
    "    }\n",
    "\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=15, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    " \n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 833   \n",
      "--------------------------------------\n",
      "833       Trainable params\n",
      "0         Non-trainable params\n",
      "833       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4/4 [00:00<00:00, 126.28it/s, v_num=97, val_mse=274.0, train_mse=301.0]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4/4 [00:00<00:00, 110.25it/s, v_num=97, val_mse=274.0, train_mse=301.0]\n",
      "{'Final Eval MAE': 13.415259, 'Final Eval R2': -0.03928233045371532}\n"
     ]
    }
   ],
   "source": [
    "# Гипотеза 2: слишком мало нейронов. Попробуем увеличить\n",
    "# Hypothesis 2: too few neurons, try more\n",
    "\n",
    "run_name = \"More Neurons Model\"\n",
    "artifact_path = \"ManyNeuronsModel\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [32, 16, 1],\n",
    "        \"activation_function_class\": torch.nn.ReLU,\n",
    "        \"lr\": 0.01\n",
    "    }\n",
    "\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=15, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    " \n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 121   \n",
      "--------------------------------------\n",
      "121       Trainable params\n",
      "0         Non-trainable params\n",
      "121       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 4/4 [00:00<00:00, 118.66it/s, v_num=98, val_mse=460.0, train_mse=503.0]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 4/4 [00:00<00:00, 105.04it/s, v_num=98, val_mse=460.0, train_mse=503.0]\n",
      "{'Final Eval MAE': 12.728006, 'Final Eval R2': 0.03846949619408124}\n"
     ]
    }
   ],
   "source": [
    "# Гипотеза 3: недостаточно гибкая функция активации. Попробуем GELU + добавим эпох обучения\n",
    "# Hypothesis 3: activation function not flexible enough. Try GELU + more training epochs\n",
    "\n",
    "run_name = \"Many Neurons, GELU, more train time\"\n",
    "artifact_path = \"NeuronsGeluTrainTime\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [12, 1],\n",
    "        \"activation_function_class\": torch.nn.GELU,\n",
    "        \"lr\": 0.01\n",
    "    }\n",
    "\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=25, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 121   \n",
      "--------------------------------------\n",
      "121       Trainable params\n",
      "0         Non-trainable params\n",
      "121       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 4/4 [00:00<00:00, 123.28it/s, v_num=99, val_mse=383.0, train_mse=412.0]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 4/4 [00:00<00:00, 108.67it/s, v_num=99, val_mse=383.0, train_mse=412.0]\n",
      "{'Final Eval MAE': 12.254554, 'Final Eval R2': 0.08864273469786377}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 121   \n",
      "--------------------------------------\n",
      "121       Trainable params\n",
      "0         Non-trainable params\n",
      "121       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 4/4 [00:00<00:00, 166.38it/s, v_num=100, val_mse=495.0, train_mse=537.0]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 4/4 [00:00<00:00, 140.33it/s, v_num=100, val_mse=495.0, train_mse=537.0]\n",
      "{'Final Eval MAE': 14.322752, 'Final Eval R2': -0.22599365637025381}\n",
      "CPU TRAIN TIME: 0.9745\n",
      "CPU PREDICT TIME: 0.0005\n",
      "GPU TRAIN TIME: 0.8386\n",
      "GPU PREDICT TIME: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# ------------ Старт лабы 3 ---------------\n",
    "#------------ lab 3 start---------------\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "\n",
    "# Замеряем скорость работы на CPU\n",
    "\n",
    "model_params = {\n",
    "    \"in_features\": train_tensor.shape[1],\n",
    "    \"layer_neurons\": [12, 1],\n",
    "    \"activation_function_class\": torch.nn.GELU,\n",
    "    \"lr\": 0.01\n",
    "}\n",
    "\n",
    "start_cpu_train = time()\n",
    "cpu_model = LightningModel(**model_params)\n",
    "\n",
    "mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=25, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "trainer.fit(cpu_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "end_cpu_train = time()\n",
    "\n",
    "start_cpu_predict = time()\n",
    "cpu_model.eval()\n",
    "preds = cpu_model(val_tensor)\n",
    "\n",
    "detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "detached_pred = preds.detach().cpu().numpy()\n",
    "end_cpu_predict = time()\n",
    "\n",
    "metrics = {\n",
    "    \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "    \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "}\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "# И на ГПУ\n",
    "start_gpu_train = time()\n",
    "gpu_model = LightningModel(**model_params)\n",
    "\n",
    "mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "train_ds.X.cuda()\n",
    "train_ds.y.cuda()\n",
    "val_ds.X.cuda()\n",
    "val_ds.y.cuda()\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=256)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=256)\n",
    "trainer = pl.Trainer(max_epochs=25, accelerator='gpu', callbacks=[mlflow_callback])\n",
    "trainer.fit(gpu_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "end_gpu_train = time()\n",
    "\n",
    "start_gpu_predict = time()\n",
    "gpu_model.eval()\n",
    "preds = gpu_model(val_tensor)\n",
    "\n",
    "detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "detached_pred = preds.detach().cpu().numpy()\n",
    "end_gpu_predict = time()\n",
    "\n",
    "metrics = {\n",
    "    \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "    \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "}\n",
    "pprint(metrics)\n",
    "\n",
    "\n",
    "print(f\"CPU TRAIN TIME: {(end_cpu_train-start_cpu_train):.4f}\")\n",
    "print(f\"CPU PREDICT TIME: {(end_cpu_predict-start_cpu_predict):.4f}\")\n",
    "print(f\"GPU TRAIN TIME: {(end_gpu_train-start_gpu_train):.4f}\")\n",
    "print(f\"GPU PREDICT TIME: {(end_gpu_predict-start_gpu_predict):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Сохраняем модельку в ONNX -----------\n",
    "# --------- Save the model to ONNX -------------\n",
    "cpu_model.to_onnx(\"cpu_model.onnx\", input_sample=val_tensor.detach().cpu())\n",
    "gpu_model.to_onnx(\"gpu_model.onnx\", input_sample=val_tensor.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "{'Final Eval MAE': 12.254554, 'Final Eval R2': 0.08864273993381688}\n",
      "0.0040\n"
     ]
    }
   ],
   "source": [
    "# Замеряем время прогноза с ONNX\n",
    "import onnxruntime\n",
    "start = time()\n",
    "\n",
    "cpu_sess = onnxruntime.InferenceSession(\"cpu_model.onnx\", providers=['CPUExecutionProvider'])\n",
    "cpu_outputs = cpu_sess.run(None, {\"onnx::Gemm_0\": val_tensor.detach().cpu().numpy()})[0]\n",
    "end = time()\n",
    "\n",
    "metrics = {\n",
    "    \"Final Eval MAE\": mean_absolute_error(y_val_tensor.detach().cpu().numpy(), cpu_outputs),\n",
    "    \"Final Eval R2\": r2_score(y_val_tensor.detach().cpu().numpy(), cpu_outputs)\n",
    "}\n",
    "print(metrics)\n",
    "print(f\"{(end-start):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "{'Final Eval MAE': 14.322752, 'Final Eval R2': -0.22599361794079398}\n",
      "0.0046\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "gpu_sess = onnxruntime.InferenceSession(\"gpu_model.onnx\")\n",
    "print(onnxruntime.get_device())\n",
    "gpu_outputs = gpu_sess.run(None, {\"onnx::Gemm_0\": val_tensor.detach().cpu().numpy()})[0]\n",
    "end = time()\n",
    "metrics = {\n",
    "    \"Final Eval MAE\": mean_absolute_error(y_val_tensor.detach().cpu().numpy(), gpu_outputs),\n",
    "    \"Final Eval R2\": r2_score(y_val_tensor.detach().cpu().numpy(), gpu_outputs)\n",
    "}\n",
    "print(metrics)\n",
    "print(f\"{(end-start):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"bento_gpu_model:7wzbhlq7ewfbhdjx\", path=\"/home/a/bentoml/models/bento_gpu_model/7wzbhlq7ewfbhdjx/\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bentoml\n",
    "import bentoml_cli.serve\n",
    "import onnx\n",
    "\n",
    "bentoml.onnx.save_model(\"bento_cpu_model\", onnx.load(\"cpu_model.onnx\"))\n",
    "bentoml.onnx.save_model(\"bento_gpu_model\", onnx.load(\"gpu_model.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='0.0.0.0', port=3000): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x70b1861b5c60>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:497\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:395\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:243\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:218\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x70b1861b5c60>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:845\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    843\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 845\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=3000): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x70b1861b5c60>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(val_tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      5\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 6\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://0.0.0.0:3000/predict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(end\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=3000): Max retries exceeded with url: /predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x70b1861b5c60>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "data = json.dumps(val_tensor.detach().cpu().tolist())\n",
    "start = time()\n",
    "r = requests.post(\"http://0.0.0.0:3000/predict\", data)\n",
    "end = time()\n",
    "print(f\"{(end-start):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code\n",
    "r.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
